{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/comparativechrono/Principles-of-Data-Science/blob/main/Week_1/Section_6_Python_Example__Simulating_Data_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba67c164",
      "metadata": {
        "id": "ba67c164"
      },
      "source": [
        "#Section 6 Python Example: Simulating Data Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adba383c",
      "metadata": {
        "id": "adba383c"
      },
      "source": [
        "Simulating data generation is a valuable technique in data science, particularly useful for testing hypotheses, validating models, and training machine learning algorithms when real datasets are incomplete, unavailable, or when privacy issues restrict their use. Python offers various tools and libraries, such as NumPy and SciPy, which can be leveraged to create synthetic datasets that closely mimic real-world data characteristics. This section provides a practical example to illustrate how to generate simulated data in Python, covering basic statistical distributions and more complex data structures."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8c20620",
      "metadata": {
        "id": "e8c20620"
      },
      "source": [
        "1. Generating Random Data with NumPy:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11160be9",
      "metadata": {
        "id": "11160be9"
      },
      "source": [
        "NumPy is a fundamental package for scientific computing in Python. It includes support for a wide range of mathematical operations and has powerful data generation capabilities. Here, we'll use NumPy to generate random data from different statistical distributions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b5b986a0",
      "metadata": {
        "id": "b5b986a0",
        "outputId": "f31a8468-c183-4ff6-d1bc-de839828de2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Integers: [52 93 15 72 61 21 83 87 75 75]\n",
            "Normal Distribution Sample Mean: 0.025354699638558926\n",
            "Normal Distribution Sample Standard Deviation: 1.0003731428167348\n",
            "Uniform Distribution Sample Mean: 0.5016124771821006\n",
            "Uniform Distribution Sample Range: (0.0032182636042786816, 0.9994137257706666)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Set seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate random integers\n",
        "random_integers = np.random.randint(1, 100, size=10)\n",
        "print(\"Random Integers:\", random_integers)\n",
        "\n",
        "# Generate random samples from a normal distribution\n",
        "normal_data = np.random.normal(loc=0, scale=1, size=1000)\n",
        "print(\"Normal Distribution Sample Mean:\", np.mean(normal_data))\n",
        "print(\"Normal Distribution Sample Standard Deviation:\", np.std(normal_data))\n",
        "\n",
        "# Generate random samples from a uniform distribution\n",
        "uniform_data = np.random.uniform(low=0, high=1, size=1000)\n",
        "print(\"Uniform Distribution Sample Mean:\", np.mean(uniform_data))\n",
        "print(\"Uniform Distribution Sample Range:\", (np.min(uniform_data), np.max(uniform_data)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0931d96a",
      "metadata": {
        "id": "0931d96a"
      },
      "source": [
        "2. Simulating a Time Series Data:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c622c0ff",
      "metadata": {
        "id": "c622c0ff"
      },
      "source": [
        "Time series data is sequential data indexed in time order, often found in economics, environmental science, or even server log data. Here’s how you might simulate a simple daily temperature dataset using Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cba67a42",
      "metadata": {
        "id": "cba67a42",
        "outputId": "66bb27fe-f359-4dde-c351-041a45468073",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simulated Daily Temperatures for 2021:\n",
            "2021-01-01    24.967142\n",
            "2021-01-02    18.617357\n",
            "2021-01-03    26.476885\n",
            "2021-01-04    35.230299\n",
            "2021-01-05    17.658466\n",
            "Freq: D, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Generate a time series of daily temperatures\n",
        "np.random.seed(42)\n",
        "days = 365\n",
        "mean_temperature = 20  # degrees Celsius\n",
        "temperature_variation = 10  # daily variation in temperature\n",
        "\n",
        "daily_temperatures = np.random.normal(loc=mean_temperature, scale=temperature_variation, size=days)\n",
        "dates = pd.date_range(start='2021-01-01', periods=days, freq='D')\n",
        "temperature_series = pd.Series(data=daily_temperatures, index=dates)\n",
        "\n",
        "print(\"Simulated Daily Temperatures for 2021:\")\n",
        "print(temperature_series.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0b962cb",
      "metadata": {
        "id": "c0b962cb"
      },
      "source": [
        "3. Creating a Synthetic Classification Dataset with Scikit-learn:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c0c2aed",
      "metadata": {
        "id": "0c0c2aed"
      },
      "source": [
        "For machine learning applications, especially in classification tasks, simulating datasets with specific properties can be very useful. Scikit-learn offers utilities for generating datasets for various machine learning tasks. Here’s how to generate a simple binary classification dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "21760776",
      "metadata": {
        "id": "21760776",
        "outputId": "57e2e2f2-f12b-4673-cde7-8268010f9a37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic Classification Dataset Preview:\n",
            "   Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
            "0   0.866690   0.563581  -0.919093  -0.533558   0.830336   0.248221   \n",
            "1   0.624825   0.901690  -0.669515  -0.921694  -0.790474   0.725767   \n",
            "2   0.484315   1.358280  -0.528156  -1.429220  -0.756351  -0.955540   \n",
            "3   0.925419   0.474106  -0.979591  -0.431315  -1.304470  -0.032695   \n",
            "4  -0.518667  -1.146568   0.561319   1.196641  -0.039555  -1.276749   \n",
            "\n",
            "   Feature_7  Feature_8  Feature_9  Feature_10  ...  Feature_12  Feature_13  \\\n",
            "0  -1.859457   0.181866  -0.856084    0.003484  ...    0.605559   -1.249347   \n",
            "1  -1.695181   0.109395   0.471468    0.457738  ...    0.649019   -0.663373   \n",
            "2  -1.785998  -0.127918  -1.422254    0.960709  ...    0.785842   -0.198320   \n",
            "3  -1.894064   0.384065   0.669673   -0.113594  ...    0.591843   -1.395164   \n",
            "4   1.692146   0.271579   0.681501   -0.745771  ...   -0.709469    0.359963   \n",
            "\n",
            "   Feature_14  Feature_15  Feature_16  Feature_17  Feature_18  Feature_19  \\\n",
            "0   -0.477657   -0.459361    0.071566   -0.849844    1.537036    1.124465   \n",
            "1    1.345420    0.481009    1.882024    0.223884    1.039670    0.900145   \n",
            "2   -1.081548   -1.606446   -0.646573    0.203464    0.714794    0.816824   \n",
            "3   -0.939880   -2.067442    0.366598   -0.089120    1.658822    1.177600   \n",
            "4    0.029756   -1.081057    0.028318    1.053153   -0.808045   -0.819116   \n",
            "\n",
            "   Feature_20  Target  \n",
            "0   -1.371601       1  \n",
            "1   -1.029645       1  \n",
            "2   -0.852423       1  \n",
            "3   -1.454025       1  \n",
            "4    0.887505       0  \n",
            "\n",
            "[5 rows x 21 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Generate a binary classification dataset\n",
        "X, y = make_classification(n_samples=100, n_features=20, n_informative=2, n_redundant=10, n_classes=2, random_state=42)\n",
        "\n",
        "# Convert to DataFrame for better visualization\n",
        "import pandas as pd\n",
        "feature_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])]\n",
        "data = pd.DataFrame(X, columns=feature_names)\n",
        "data['Target'] = y\n",
        "\n",
        "print(\"Synthetic Classification Dataset Preview:\")\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01566604",
      "metadata": {
        "id": "01566604"
      },
      "source": [
        "These examples demonstrate the flexibility and power of Python for generating synthetic data. Such simulations are essential tools in data science, enabling researchers and analysts to perform robust testing and development of analytical models and methods. Simulated data must be used judiciously, especially in ensuring that it reflects the characteristics of real data closely enough to provide meaningful insights when applied to actual scenarios."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de907e16",
      "metadata": {
        "id": "de907e16"
      },
      "source": [
        "References:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "045cc5d5",
      "metadata": {
        "id": "045cc5d5"
      },
      "source": [
        "VanderPlas, J. (2016). Python Data Science Handbook: Essential Tools for Working with Data. O'Reilly Media."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eef118e8",
      "metadata": {
        "id": "eef118e8"
      },
      "source": [
        "McKinney, W. (2012). Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython. O'Reilly Media."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a2b899b",
      "metadata": {
        "id": "3a2b899b"
      },
      "source": [
        "Pedregosa, F., et al. (2011). Scikit-learn: Machine Learning in Python, JMLR 12, pp. 2825-2830."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
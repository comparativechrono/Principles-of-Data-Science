{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/comparativechrono/Principles-of-Data-Science/blob/main/Week_1/Section_8_Python_Example__Implementing_Statistical_Calculations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae6b36c2",
      "metadata": {
        "id": "ae6b36c2"
      },
      "source": [
        "# Section 8 Python Example Implementing Statistical Calculations\n",
        "\n",
        "Statistical calculations are a fundamental aspect of data analysis in data science, allowing us to summarize, interpret, and derive insights from data. Python, equipped with powerful libraries like NumPy and SciPy, provides extensive functionalities for performing these calculations efficiently. This section illustrates how to implement essential statistical calculations in Python, including measures of central tendency, variability, hypothesis testing, and regression analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68eea8f0",
      "metadata": {
        "id": "68eea8f0"
      },
      "source": [
        "1. Measures of Central Tendency and Variability:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9679deb0",
      "metadata": {
        "id": "9679deb0"
      },
      "source": [
        "Using Python's NumPy library, we can easily calculate the mean, median, and standard deviation, which are basic measures of central tendency and variability. Here's an example using a sample dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "562a03d5",
      "metadata": {
        "id": "562a03d5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "data = np.array([23, 29, 20, 32, 34, 29, 27, 24, 21, 33, 25, 31])\n",
        "\n",
        "# Calculate measures of central tendency\n",
        "mean = np.mean(data)\n",
        "median = np.median(data)\n",
        "mode = np.bincount(data).argmax()  # Simple mode (most common value)\n",
        "\n",
        "# Calculate measures of variability\n",
        "std_deviation = np.std(data)\n",
        "variance = np.var(data)\n",
        "\n",
        "print(\"Mean:\", mean)\n",
        "print(\"Median:\", median)\n",
        "print(\"Mode:\", mode)\n",
        "print(\"Standard Deviation:\", std_deviation)\n",
        "print(\"Variance:\", variance)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9026dd5f",
      "metadata": {
        "id": "9026dd5f"
      },
      "source": [
        "2. Probability Distributions:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bac094f5",
      "metadata": {
        "id": "bac094f5"
      },
      "source": [
        "Let’s simulate data from a normal distribution and calculate probabilities using the SciPy library, which complements NumPy with more advanced statistical functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03296a2e",
      "metadata": {
        "id": "03296a2e"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import norm\n",
        "\n",
        "# Generate random data from a normal distribution\n",
        "normal_data = np.random.normal(loc=0, scale=1, size=1000)\n",
        "\n",
        "# Calculate probabilities\n",
        "prob_less_than_zero = norm.cdf(x=0, loc=np.mean(normal_data), scale=np.std(normal_data))\n",
        "\n",
        "print(\"Probability of less than zero:\", prob_less_than_zero)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "914ab111",
      "metadata": {
        "id": "914ab111"
      },
      "source": [
        "3. Hypothesis Testing:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7344768d",
      "metadata": {
        "id": "7344768d"
      },
      "source": [
        "We can perform a simple t-test to determine whether the means of two independent samples are significantly different. Here’s how you might use SciPy to perform this test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8495cf5",
      "metadata": {
        "id": "c8495cf5"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Sample data (two groups)\n",
        "group1 = np.random.normal(30, 10, 100)\n",
        "group2 = np.random.normal(35, 10, 100)\n",
        "\n",
        "# Perform a t-test\n",
        "t_stat, p_value = ttest_ind(group1, group2)\n",
        "\n",
        "print(\"t-statistic:\", t_stat)\n",
        "print(\"p-value:\", p_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f64c3e29",
      "metadata": {
        "id": "f64c3e29"
      },
      "source": [
        "4. Regression Analysis:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f69d0eb",
      "metadata": {
        "id": "6f69d0eb"
      },
      "source": [
        "For regression analysis, the statsmodels library provides comprehensive classes and functions. Here's an example of performing linear regression:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b32f4ba3",
      "metadata": {
        "id": "b32f4ba3"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Dependent and independent variables\n",
        "Y = np.array([25, 30, 35, 40, 45])  # Dependent variable (e.g., salary)\n",
        "X = np.array([5, 10, 15, 20, 25])  # Independent variable (e.g., years of experience)\n",
        "X = sm.add_constant(X)  # Adds a constant term to the predictor\n",
        "\n",
        "# Fit the regression model\n",
        "model = sm.OLS(Y, X).fit()\n",
        "\n",
        "# Print out the statistics\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "459b0b0a",
      "metadata": {
        "id": "459b0b0a"
      },
      "source": [
        "These examples demonstrate how Python can be effectively used to perform a range of statistical calculations, from simple measures of central tendency to more complex analyses like hypothesis testing and regression. By leveraging Python’s libraries, data scientists can efficiently process and analyse large datasets, applying statistical techniques to derive actionable insights and make informed decisions based on data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e216e4c6",
      "metadata": {
        "id": "e216e4c6"
      },
      "source": [
        "References:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57b3fd0e",
      "metadata": {
        "id": "57b3fd0e"
      },
      "source": [
        "McKinney, W. (2012). Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython. O'Reilly Media."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7152384b",
      "metadata": {
        "id": "7152384b"
      },
      "source": [
        "Bressert, E. (2012). SciPy and NumPy: An Overview for Developers. O'Reilly Media."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9e8b75a",
      "metadata": {
        "id": "d9e8b75a"
      },
      "source": [
        "Seabold, S., & Perktold, J. (2010). \"Statsmodels: Econometric and statistical modeling with Python.\" Proceedings of the 9th Python in Science Conference."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/comparativechrono/Principles-of-Data-Science/blob/main/Week_1/Section_10_Python_Example__Analyzing_a_Dataset_Relevant_to_Your_Field.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56ee4906",
      "metadata": {
        "id": "56ee4906"
      },
      "source": [
        "#Python Example: Analyzing a Dataset Relevant to Your Field"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c080c4f4",
      "metadata": {
        "id": "c080c4f4"
      },
      "source": [
        "This section demonstrates a practical Python example of data analysis, specifically designed for data scientists who might be working in the retail sector. This example will walk through the process of loading data, performing exploratory data analysis (EDA), building a simple predictive model, and interpreting the results. The focus will be on analysing customer purchase data to identify patterns and predict future buying behaviors, using Python libraries such as Pandas for data manipulation and Scikit-learn for modeling."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16eebc72",
      "metadata": {
        "id": "16eebc72"
      },
      "source": [
        "1. Loading and Inspecting the Data:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92b11334",
      "metadata": {
        "id": "92b11334"
      },
      "source": [
        "We'll start by loading a dataset containing customer purchases from a retail store. The dataset includes customer demographics and purchase history. We will use Pandas, a powerful data manipulation library in Python, to load and inspect our dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92bad8b3",
      "metadata": {
        "id": "92bad8b3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('customer_purchases.csv')\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "print(data.head())\n",
        "\n",
        "# Get a quick overview of the dataset\n",
        "print(data.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54fe9cbe",
      "metadata": {
        "id": "54fe9cbe"
      },
      "source": [
        "2. Data Cleaning:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4791414e",
      "metadata": {
        "id": "4791414e"
      },
      "source": [
        "Data cleaning is a crucial step before any analysis. We'll clean the data by handling missing values, removing duplicates, and converting data types if necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fbf9852",
      "metadata": {
        "id": "5fbf9852"
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Fill missing values with the median or mode as appropriate\n",
        "data['age'].fillna(data['age'].median(), inplace=True)\n",
        "data['last_purchase'].fillna(data['last_purchase'].mode()[0], inplace=True)\n",
        "\n",
        "# Remove any duplicates\n",
        "data.drop_duplicates(inplace=True)\n",
        "\n",
        "# Convert data types\n",
        "data['customer_id'] = data['customer_id'].astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5eede89f",
      "metadata": {
        "id": "5eede89f"
      },
      "source": [
        "3. Exploratory Data Analysis (EDA):"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "071aeb06",
      "metadata": {
        "id": "071aeb06"
      },
      "source": [
        "EDA involves summarizing the main characteristics of the dataset, often with visual methods. We'll use Pandas for data manipulation and Matplotlib for visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "077e72e9",
      "metadata": {
        "id": "077e72e9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualizing the distribution of ages\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.hist(data['age'], bins=30, color='blue', alpha=0.7)\n",
        "plt.title('Distribution of Age')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# Analyzing purchase frequency\n",
        "purchase_counts = data['last_purchase'].value_counts()\n",
        "purchase_counts.plot(kind='bar')\n",
        "plt.title('Purchase Category Frequency')\n",
        "plt.xlabel('Category')\n",
        "plt.ylabel('Number of Purchases')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b875a51a",
      "metadata": {
        "id": "b875a51a"
      },
      "source": [
        "4. Building a Predictive Model:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e243c5f",
      "metadata": {
        "id": "6e243c5f"
      },
      "source": [
        "We'll use a simple logistic regression model to predict whether a customer will make a purchase in a specific category based on their age and last purchase category. Scikit-learn is a library that provides simple and efficient tools for data mining and data analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcd4374c",
      "metadata": {
        "id": "fcd4374c"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Feature selection\n",
        "features = data[['age', 'last_purchase']]\n",
        "target = data['will_purchase_again']  # this is a binary variable (yes/no)\n",
        "\n",
        "# Encoding categorical variables\n",
        "features = pd.get_dummies(features)\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the test set results\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluating the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcec4a13",
      "metadata": {
        "id": "dcec4a13"
      },
      "source": [
        "5. Interpreting the Results:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f615194",
      "metadata": {
        "id": "4f615194"
      },
      "source": [
        "The final step is to interpret the results of our logistic regression model. An accuracy metric will tell us how often the model predicts correctly. Further interpretation might involve looking at the coefficients of the model to understand the impact of different features on the likelihood of a customer making a purchase."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
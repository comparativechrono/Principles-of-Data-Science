{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/comparativechrono/Principles-of-Data-Science/blob/main/Week_8/Section_10_Python_Example__Model_Deployment_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Section 10: Python example - model deployment basics"
      ],
      "metadata": {
        "id": "4PCklU-k9zua"
      },
      "id": "4PCklU-k9zua"
    },
    {
      "cell_type": "markdown",
      "id": "1cf1872c",
      "metadata": {
        "id": "1cf1872c"
      },
      "source": [
        "Deploying a machine learning model involves making it available to end-users or systems, typically via an application or service. This section demonstrates a basic example of deploying a machine learning model using Python. We will cover the process of preparing a model for deployment, creating a simple web application using Flask to serve predictions, and discussing common practices for deployment. Please note that this will not run as written in a Jupyter notebook - you can run up to step 3, but then will need to run step 4 on the CLI, to send a POST to your server"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b7d3366",
      "metadata": {
        "id": "7b7d3366"
      },
      "source": [
        "1. Setting Up the Environment:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b61c9eda",
      "metadata": {
        "id": "b61c9eda"
      },
      "source": [
        "First, ensure that you have all necessary tools and libraries installed. For this example, you will need Flask to create the web server and joblib for saving and loading the model. Install these using pip if you haven't already:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59bddc86",
      "metadata": {
        "id": "59bddc86"
      },
      "outputs": [],
      "source": [
        "pip install Flask joblib scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55329243",
      "metadata": {
        "id": "55329243"
      },
      "source": [
        "2. Preparing the Model:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d99ba3c0",
      "metadata": {
        "id": "d99ba3c0"
      },
      "source": [
        "Before deployment, a model must be trained and validated to ensure it performs well. For simplicity, letâ€™s train a basic logistic regression model using scikit-learn on the Iris dataset. Once trained, the model is saved to disk using joblib, which allows us to easily load it later without retraining."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3e070f4",
      "metadata": {
        "id": "b3e070f4"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from joblib import dump\n",
        "\n",
        "# Load data\n",
        "iris = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a logistic regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save the model to disk\n",
        "dump(model, 'iris_model.joblib')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c9fa3f4",
      "metadata": {
        "id": "1c9fa3f4"
      },
      "source": [
        "3. Creating a Flask Application to Serve the Model:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7e7d2f6",
      "metadata": {
        "id": "f7e7d2f6"
      },
      "source": [
        "With the model saved, you can now create a Flask application to serve predictions. The application will expose an HTTP endpoint where users can send data and receive predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "035d203a",
      "metadata": {
        "id": "035d203a"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from joblib import load\n",
        "\n",
        "# Load the trained model\n",
        "model = load('iris_model.joblib')\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    # Extract features from the request\n",
        "    feature_array = request.get_json(force=True)['features']\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict([feature_array])\n",
        "    return jsonify({'prediction': list(prediction)})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True, port=5000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17bbf085",
      "metadata": {
        "id": "17bbf085"
      },
      "source": [
        "4. Testing the Deployment:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "baf484b6",
      "metadata": {
        "id": "baf484b6"
      },
      "source": [
        "To test the deployed model, you can use tools like curl or Postman to send a POST request to your Flask app:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8439d110",
      "metadata": {
        "id": "8439d110"
      },
      "outputs": [],
      "source": [
        "curl -X POST -H \"Content-Type: application/json\" -d '{\"features\":[5.9, 3.0, 5.1, 1.8]}' http://localhost:5000/predict"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e24c9db",
      "metadata": {
        "id": "7e24c9db"
      },
      "source": [
        "This request simulates sending a data point to the model, and you should receive a prediction in response."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a236af0e",
      "metadata": {
        "id": "a236af0e"
      },
      "source": [
        "5. Deployment Considerations:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20ac1c53",
      "metadata": {
        "id": "20ac1c53"
      },
      "source": [
        "When deploying a model, consider the following:\n",
        "\n",
        "*  Security: Ensure your application handles data securely, especially if sensitive information is involved.\n",
        "*  Scalability: If expecting high traffic, consider scaling your deployment to handle multiple requests simultaneously.\n",
        "*  Monitoring: Set up logging and monitoring to track the application's performance and health over time.\n",
        "*  Updating: Plan for periodic updates to the model as new data becomes available or when performance dips."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35040729",
      "metadata": {
        "id": "35040729"
      },
      "source": [
        "6. Conclusion:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fc2b74e",
      "metadata": {
        "id": "6fc2b74e"
      },
      "source": [
        "Deploying a machine learning model into production requires careful planning and testing to ensure it performs well in the real world. Python, with libraries like Flask and joblib, provides a straightforward path for deployment, making it accessible for data scientists to bring their models to life. While this example provides a basic setup, the principles can be extended to more complex, robust applications suitable for real-world scenarios."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/comparativechrono/Principles-of-Data-Science/blob/main/Week_8/Section_8_Python_Example__Implementing_Random_Forests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 8: Python example - implementing random forests"
      ],
      "metadata": {
        "id": "vpx8_Yxu9aEt"
      },
      "id": "vpx8_Yxu9aEt"
    },
    {
      "cell_type": "markdown",
      "id": "1f6cc087",
      "metadata": {
        "id": "1f6cc087"
      },
      "source": [
        "Random Forests are a popular ensemble learning method that builds on the concept of bagging. This technique involves constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Random Forests aim to improve over decision trees by reducing overfitting without significantly increasing error due to bias. This section provides a step-by-step guide to implementing a Random Forest model in Python using scikit-learn."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa8bc265",
      "metadata": {
        "id": "aa8bc265"
      },
      "source": [
        "1. Setting Up the Environment:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9976d8b2",
      "metadata": {
        "id": "9976d8b2"
      },
      "source": [
        "To implement a Random Forest model, ensure your Python setup includes scikit-learn, a comprehensive library that offers robust tools for machine learning, including the Random Forest algorithm. If itâ€™s not installed, you can add it via pip:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf053c03",
      "metadata": {
        "id": "cf053c03"
      },
      "outputs": [],
      "source": [
        "pip install scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5980265a",
      "metadata": {
        "id": "5980265a"
      },
      "source": [
        "2. Importing Required Libraries:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f90dd71",
      "metadata": {
        "id": "0f90dd71"
      },
      "source": [
        "We will need scikit-learn for modeling, Pandas for data manipulation, and NumPy for numerical operations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e31ce4e",
      "metadata": {
        "id": "3e31ce4e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e5560d5",
      "metadata": {
        "id": "1e5560d5"
      },
      "source": [
        "3. Preparing the Data:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e476f1b",
      "metadata": {
        "id": "9e476f1b"
      },
      "source": [
        "For this example, let's use a dataset from scikit-learn's dataset module. We'll use the Iris dataset, which is a simple, widely-used dataset for classification tasks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dac8b2fa",
      "metadata": {
        "id": "dac8b2fa"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "# Convert to DataFrame for easier handling\n",
        "df = pd.DataFrame(data=X, columns=data.feature_names)\n",
        "df['target'] = y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6939317",
      "metadata": {
        "id": "c6939317"
      },
      "source": [
        "4. Splitting the Data:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "603f306d",
      "metadata": {
        "id": "603f306d"
      },
      "source": [
        "Divide the data into training and test sets to ensure we have a way to validate the performance of our Random Forest model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0732eb7",
      "metadata": {
        "id": "e0732eb7"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df[data.feature_names], df['target'], test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79279358",
      "metadata": {
        "id": "79279358"
      },
      "source": [
        "5. Building the Random Forest Model:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a52f63a",
      "metadata": {
        "id": "3a52f63a"
      },
      "source": [
        "Instantiate and train a Random Forest classifier. We'll use 100 trees in the forest:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd96c3f9",
      "metadata": {
        "id": "bd96c3f9"
      },
      "outputs": [],
      "source": [
        "# Initialize the Random Forest classifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "# Train the model\n",
        "rf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "950871c7",
      "metadata": {
        "id": "950871c7"
      },
      "source": [
        "6. Evaluating the Model:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a056e0cb",
      "metadata": {
        "id": "a056e0cb"
      },
      "source": [
        "After training the model, evaluate its performance on the test data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cff186b",
      "metadata": {
        "id": "3cff186b"
      },
      "outputs": [],
      "source": [
        "# Predict on the test set\n",
        "y_pred = rf.predict(X_test)\n",
        "# Evaluate the predictions\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy of the Random Forest model: {accuracy:.2f}')\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4351584",
      "metadata": {
        "id": "e4351584"
      },
      "source": [
        "7. Feature Importance:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbc3d007",
      "metadata": {
        "id": "fbc3d007"
      },
      "source": [
        "One of the advantages of Random Forests is their ability to determine the importance of features in the classification:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39a8604d",
      "metadata": {
        "id": "39a8604d"
      },
      "outputs": [],
      "source": [
        "# Get feature importances\n",
        "importances = rf.feature_importances_\n",
        "# Print the name and importance of each feature\n",
        "for feature, importance in zip(data.feature_names, importances):\n",
        "  print(f'{feature}: {importance:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66026e1a",
      "metadata": {
        "id": "66026e1a"
      },
      "source": [
        "8. Visualization of Feature Importance:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f01baee7",
      "metadata": {
        "id": "f01baee7"
      },
      "source": [
        "Visualize the feature importances to better understand which features are driving the model predictions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e72a0df",
      "metadata": {
        "id": "0e72a0df"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Sorting the features by importance\n",
        "indices = np.argsort(importances)[::-1]\n",
        "plt.figure()\n",
        "plt.title(\"Feature importances\")\n",
        "plt.bar(range(X_train.shape[1]), importances[indices], align=\"center\")\n",
        "plt.xticks(range(X_train.shape[1]), np.array(data.feature_names)[indices], rotation=90)\n",
        "plt.xlim([-1, X_train.shape[1]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2a6b789",
      "metadata": {
        "id": "a2a6b789"
      },
      "source": [
        "9. Conclusion:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3e7cc88",
      "metadata": {
        "id": "c3e7cc88"
      },
      "source": [
        "Implementing a Random Forest in Python using scikit-learn is straightforward and provides a powerful tool capable of handling both classification and regression tasks effectively. This model is not only good at prediction but also provides insights into the importance of different features, making it a valuable tool for understanding complex datasets. The inherent ability of Random Forests to manage overfitting, while maintaining accuracy, makes them highly favourable for many practical applications in machine learning."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/comparativechrono/Principles-of-Data-Science/blob/main/Week_8/Section_6_Python_Example__Cross_Validation_Techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Section 6: Python example - cross-validation techniques"
      ],
      "metadata": {
        "id": "CrFOKA_I7pPC"
      },
      "id": "CrFOKA_I7pPC"
    },
    {
      "cell_type": "markdown",
      "id": "c6f6b8b5",
      "metadata": {
        "id": "c6f6b8b5"
      },
      "source": [
        "Cross-validation is a cornerstone technique in model validation, crucial for assessing how the results of a statistical analysis will generalize to an independent data set. It is particularly vital in scenarios where the goal is to predict, and one needs to estimate how accurately a predictive model will perform in practice. This section provides a detailed Python example demonstrating how to implement various cross-validation techniques using the scikit-learn library."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee18f08d",
      "metadata": {
        "id": "ee18f08d"
      },
      "source": [
        "1. Setting Up the Environment:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8dd0499",
      "metadata": {
        "id": "a8dd0499"
      },
      "source": [
        "Ensure that your Python environment includes scikit-learn, a versatile library that offers robust tools for cross-validation. Install it via pip if it's not already included:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bba5ee0",
      "metadata": {
        "id": "2bba5ee0"
      },
      "outputs": [],
      "source": [
        "pip install scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b7fd295",
      "metadata": {
        "id": "6b7fd295"
      },
      "source": [
        "2. Importing Required Libraries:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df0bacb6",
      "metadata": {
        "id": "df0bacb6"
      },
      "source": [
        "Begin by importing necessary libraries. We'll need scikit-learn for the modeling and cross-validation tools, pandas for data manipulation, and NumPy for numerical operations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8778c293",
      "metadata": {
        "id": "8778c293"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score, LeaveOneOut\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be0925c2",
      "metadata": {
        "id": "be0925c2"
      },
      "source": [
        "3. Preparing the Data:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0355649",
      "metadata": {
        "id": "d0355649"
      },
      "source": [
        "We'll use a synthetic dataset for classification, which scikit-learn can generate easily:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "726d740f",
      "metadata": {
        "id": "726d740f"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=3, n_redundant=0, n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)\n",
        "# Convert to DataFrame for easier manipulation\n",
        "df = pd.DataFrame(X, columns=[f'Feature_{i}' for i in range(20)])\n",
        "df['Target'] = y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea165e07",
      "metadata": {
        "id": "ea165e07"
      },
      "source": [
        "4. Implementing Cross-Validation:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2eee8c59",
      "metadata": {
        "id": "2eee8c59"
      },
      "source": [
        "K-Fold Cross-Validation:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07913eb5",
      "metadata": {
        "id": "07913eb5"
      },
      "source": [
        "K-Fold is a widely used method in cross-validation that involves dividing the data into 'k' consecutive folds, ensuring every data point gets to be in a test set exactly once and in a training set 'k-1' times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "152ff885",
      "metadata": {
        "id": "152ff885"
      },
      "outputs": [],
      "source": [
        "# Setting up 10-Fold Cross-Validation\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
        "# Model instantiation\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=1)\n",
        "# Array to store scores\n",
        "scores = []\n",
        "for train_index, test_index in kfold.split(X):\n",
        "  X_train, X_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "  model.fit(X_train, y_train)\n",
        "  predictions = model.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test, predictions)\n",
        "  scores.append(accuracy)\n",
        "print(f'K-Fold Cross-Validation Scores: {scores}')\n",
        "print(f'Mean Accuracy: {np.mean(scores)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39714d8d",
      "metadata": {
        "id": "39714d8d"
      },
      "source": [
        "Leave-One-Out Cross-Validation:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43bf4daf",
      "metadata": {
        "id": "43bf4daf"
      },
      "source": [
        "Leave-One-Out (LOO) is another technique, which is a particular case of k-fold cross-validation where the number of folds equals the number of data points. It's more computationally expensive but provides a thorough assessment of model stability and effectiveness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79bea35a",
      "metadata": {
        "id": "79bea35a"
      },
      "outputs": [],
      "source": [
        "# Using Leave-One-Out Cross-Validation\n",
        "loo = LeaveOneOut()\n",
        "scores_loo = []\n",
        "for train_index, test_index in loo.split(X):\n",
        "  X_train, X_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "  model.fit(X_train, y_train)\n",
        "  prediction = model.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test, prediction)\n",
        "  scores_loo.append(accuracy)\n",
        "print(f'Leave-One-Out Cross-Validation Score: {np.mean(scores_loo)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9d30b20",
      "metadata": {
        "id": "f9d30b20"
      },
      "source": [
        "Bootstrap Method:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f178427",
      "metadata": {
        "id": "9f178427"
      },
      "source": [
        "Bootstrap involves randomly selecting a subset of data for each sample with replacement and typically used to estimate summary statistics. We'll use bootstrapping to assess the stability of our model's performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b1e66c4",
      "metadata": {
        "id": "2b1e66c4"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import resample\n",
        "# Define the number of bootstrap samples\n",
        "n_iterations = 1000\n",
        "n_size = int(len(df) * 0.50) # 50% of the dataset\n",
        "# Model instantiation\n",
        "model = RandomForestClassifier(n_estimators=100)\n",
        "scores_bootstrap = []\n",
        "for i in range(n_iterations):\n",
        "  # Prepare train and test sets\n",
        "  train = resample(df, n_samples=n_size)\n",
        "  test = df[~df.index.isin(train.index)]\n",
        "  X_train, y_train = train.drop('Target', axis=1), train['Target']\n",
        "  X_test, y_test = test.drop('Target', axis=1), test['Target']\n",
        "  # Fit model\n",
        "  model.fit(X_train, y_train)\n",
        "  # Evaluate model\n",
        "  predictions = model.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test, predictions)\n",
        "  scores_bootstrap.append(accuracy)\n",
        "# Calculating the confidence intervals of model accuracy\n",
        "alpha = 0.95 p = ((1.0-alpha)/2.0) * 100\n",
        "lower = max(0.0, np.percentile(scores_bootstrap, p))\n",
        "p = (alpha+((1.0-alpha)/2.0)) * 100\n",
        "upper = min(1.0, np.percentile(scores_bootstrap, p))\n",
        "print('Bootstrap Cross-Validation Score (95%% confidence interval): %.1f%% (%.1f%%, %.1f%%)' % (np.mean(scores_bootstrap)*100, lower*100, upper*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6c15f87",
      "metadata": {
        "id": "b6c15f87"
      },
      "source": [
        "## Explanation:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72c8daa9",
      "metadata": {
        "id": "72c8daa9"
      },
      "source": [
        "In this example:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00ee465e",
      "metadata": {
        "id": "00ee465e"
      },
      "source": [
        "We set up 1000 iterations (n_iterations) for the bootstrap process, where in each iteration, a subset of data is randomly selected with replacement."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4263aa0",
      "metadata": {
        "id": "b4263aa0"
      },
      "source": [
        "The size of each bootstrap sample is set to 50% of the original data, but this can be adjusted depending on the specifics of your dataset and the stability of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2195881",
      "metadata": {
        "id": "d2195881"
      },
      "source": [
        "We train a RandomForestClassifier on each of these bootstrap samples."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fa3c37c",
      "metadata": {
        "id": "6fa3c37c"
      },
      "source": [
        "The model's accuracy is recorded for each iteration."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9551c4e9",
      "metadata": {
        "id": "9551c4e9"
      },
      "source": [
        "Finally, we calculate the 95% confidence intervals from the bootstrap results, providing a range that contains the true model accuracy with 95% confidence."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4250a2d8",
      "metadata": {
        "id": "4250a2d8"
      },
      "source": [
        "This bootstrap approach helps in understanding the variability and the reliability of the model's performance, complementing other cross-validation techniques like K-Fold and LOO, which primarily focus on model validation and stability across different subsets of the dataset. By integrating bootstrapping, you gain deeper insights into the potential variability in your model’s performance due to sample-specific idiosyncrasies, which is invaluable in practical applications where predictions are subject to uncertainty."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78762cfa",
      "metadata": {
        "id": "78762cfa"
      },
      "source": [
        "5. Conclusion:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f42e9528",
      "metadata": {
        "id": "f42e9528"
      },
      "source": [
        "Implementing cross-validation in Python using scikit-learn is a powerful way to evaluate the generalizability and stability of predictive models. By leveraging techniques like K-Fold and Leave-One-Out cross-validation, data scientists can rigorously assess model performance, helping to ensure that the models are robust and perform well across different subsets of data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7343b4f0",
      "metadata": {
        "id": "7343b4f0"
      },
      "source": [
        "Bootstrapping is a powerful statistical method used to estimate quantities about a population by averaging estimates from multiple small data samples, technically known as resampling with replacement. This technique is particularly useful for assessing the reliability of model estimates and providing measures of accuracy such as the standard error and confidence intervals."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92db6745",
      "metadata": {
        "id": "92db6745"
      },
      "source": [
        "These approaches are indispensable in predictive modelling, particularly when dealing with limited data or when aiming to achieve highly accurate predictions."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/comparativechrono/Principles-of-Data-Science/blob/main/Week_3/Section_6_Python_Example__Implementing_a_Pattern_Recognition_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Section 6 - Implementing a pattern recognition model"
      ],
      "metadata": {
        "id": "pwnTPGUYZB5h"
      },
      "id": "pwnTPGUYZB5h"
    },
    {
      "cell_type": "markdown",
      "id": "5dbde1c4",
      "metadata": {
        "id": "5dbde1c4"
      },
      "source": [
        "Pattern recognition models are essential for interpreting complex data and identifying key patterns within it. These models can automate the process of decision-making in various applications, from image recognition to natural language processing. This section demonstrates how to implement a basic pattern recognition model using Python, specifically focusing on a text classification task. We will use the scikit-learn library to build a model that classifies news articles into different categories based on their content."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dab8ed1",
      "metadata": {
        "id": "7dab8ed1"
      },
      "source": [
        "1. Setting Up the Environment:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9420ba2",
      "metadata": {
        "id": "d9420ba2"
      },
      "source": [
        "First, ensure that you have Python installed along with the scikit-learn package. If scikit-learn is not installed, you can install it using pip:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3ea495e",
      "metadata": {
        "id": "d3ea495e"
      },
      "outputs": [],
      "source": [
        "pip install scikit-learn numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2946f703",
      "metadata": {
        "id": "2946f703"
      },
      "source": [
        "2. Importing Required Libraries:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28a40518",
      "metadata": {
        "id": "28a40518"
      },
      "source": [
        "Import the necessary libraries. We’ll use scikit-learn for creating and training the model, and numpy for handling numerical operations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c26a0ef",
      "metadata": {
        "id": "2c26a0ef"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e654ed2",
      "metadata": {
        "id": "0e654ed2"
      },
      "source": [
        "3. Loading the Data:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7a0eebd",
      "metadata": {
        "id": "f7a0eebd"
      },
      "source": [
        "For this example, we'll use the 20 Newsgroups dataset, which is a collection of approximately 20,000 newsgroup documents, partitioned across 20 different newsgroups. This dataset is built into scikit-learn and can be easily loaded:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2640295",
      "metadata": {
        "id": "c2640295"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "data = fetch_20newsgroups()\n",
        "categories = data.target_names\n",
        "\n",
        "# For simplicity, we'll use just four categories\n",
        "categories = ['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']\n",
        "train = fetch_20newsgroups(subset='train', categories=categories)\n",
        "test = fetch_20newsgroups(subset='test', categories=categories)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69b3b103",
      "metadata": {
        "id": "69b3b103"
      },
      "source": [
        "4. Preprocessing the Data:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb43ef74",
      "metadata": {
        "id": "fb43ef74"
      },
      "source": [
        "Text data needs to be converted into a format that the model can understand, typically using a vectorization technique. We'll use TF-IDF vectorization, which reflects the importance of a word to a document in a corpus:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "929f9987",
      "metadata": {
        "id": "929f9987"
      },
      "outputs": [],
      "source": [
        "# Create a TF-IDF vectorizer and Naive Bayes classifier pipeline\n",
        "model = make_pipeline(TfidfVectorizer(), MultinomialNB())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93267706",
      "metadata": {
        "id": "93267706"
      },
      "source": [
        "5. Training the Model:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f3a8d87",
      "metadata": {
        "id": "3f3a8d87"
      },
      "source": [
        "Train the model using the training data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59025453",
      "metadata": {
        "id": "59025453"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "model.fit(train.data, train.target)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ba71d43",
      "metadata": {
        "id": "5ba71d43"
      },
      "source": [
        "6. Evaluating the Model:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6ecf338",
      "metadata": {
        "id": "f6ecf338"
      },
      "source": [
        "After training, evaluate the model’s performance on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8183bab3",
      "metadata": {
        "id": "8183bab3"
      },
      "outputs": [],
      "source": [
        "# Predict the categories of the test data\n",
        "predicted_categories = model.predict(test.data)\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = accuracy_score(test.target, predicted_categories)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Display a confusion matrix\n",
        "mat = confusion_matrix(test.target, predicted_categories)\n",
        "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
        "            xticklabels=train.target_names, yticklabels=train.target_names)\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8626a914",
      "metadata": {
        "id": "8626a914"
      },
      "source": [
        "7. Conclusion:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bb046c9",
      "metadata": {
        "id": "5bb046c9"
      },
      "source": [
        "This Python example illustrates how to implement a basic pattern recognition model using a text classification task. By employing TF-IDF for feature extraction and a Naive Bayes classifier, we successfully categorized news articles into distinct topics. This example highlights the power of machine learning in automatically recognizing patterns in text data, which can be extended to various other domains of pattern recognition."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0acc0dd2",
      "metadata": {
        "id": "0acc0dd2"
      },
      "source": [
        "Pattern recognition models like the one demonstrated here are powerful tools for data analysis, enabling the automation of complex decision-making processes and providing valuable insights from large datasets. As technology evolves, the application and efficacy of these models are expected to enhance further, driving advancements across multiple fields of study and industry sectors."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
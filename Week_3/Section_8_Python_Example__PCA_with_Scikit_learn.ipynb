{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/comparativechrono/Principles-of-Data-Science/blob/main/Week_3/Section_8_Python_Example__PCA_with_Scikit_learn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Section 8 - PCA with Scikit-learn"
      ],
      "metadata": {
        "id": "CqqevK5va-Kh"
      },
      "id": "CqqevK5va-Kh"
    },
    {
      "cell_type": "markdown",
      "id": "e10cde06",
      "metadata": {
        "id": "e10cde06"
      },
      "source": [
        "Principal Component Analysis (PCA) is one of the most commonly used techniques for dimensionality reduction in data science. PCA reduces the dimensionality of data by transforming the original variables into a new set of variables, which are linear combinations of the original variables. These new variables, called principal components, are orthogonal and ranked according to the variance of data along them, which ensures that the first few retain most of the variation present in all of the original variables. This notebook demonstrates how to implement PCA using Python's scikit-learn library, focusing on a dataset with multiple features to illustrate how PCA can simplify the data while retaining the essential information."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fc39c9e",
      "metadata": {
        "id": "2fc39c9e"
      },
      "source": [
        "1. Setting Up the Environment:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f1b61f8",
      "metadata": {
        "id": "7f1b61f8"
      },
      "source": [
        "Ensure you have the necessary Python packages installed. scikit-learn is used for PCA, and matplotlib for plotting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c528b87d",
      "metadata": {
        "id": "c528b87d"
      },
      "outputs": [],
      "source": [
        "pip install numpy matplotlib scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b53009c1",
      "metadata": {
        "id": "b53009c1"
      },
      "source": [
        "2. Importing Required Libraries:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f227ba2",
      "metadata": {
        "id": "1f227ba2"
      },
      "source": [
        "Start by importing the libraries needed for data manipulation, PCA, and plotting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "188d22f6",
      "metadata": {
        "id": "188d22f6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import load_iris"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fb20a1a",
      "metadata": {
        "id": "1fb20a1a"
      },
      "source": [
        "3. Loading and Preprocessing Data:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2644f3d0",
      "metadata": {
        "id": "2644f3d0"
      },
      "source": [
        "For this example, we'll use the Iris dataset, which is a classic dataset in pattern recognition containing the sepal and petal measurements of three species of Iris flowers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0c7969a",
      "metadata": {
        "id": "f0c7969a"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "feature_names = data.feature_names\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fbdb0c9",
      "metadata": {
        "id": "7fbdb0c9"
      },
      "source": [
        "4. Applying PCA:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e14578de",
      "metadata": {
        "id": "e14578de"
      },
      "source": [
        "We'll perform PCA to reduce the dimensions from four to two. This reduction allows us to visualize the data easily without losing much information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a3e9671",
      "metadata": {
        "id": "0a3e9671"
      },
      "outputs": [],
      "source": [
        "# Initialize PCA and reduce to two dimensions\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Explained variance ratio\n",
        "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "beae4c29",
      "metadata": {
        "id": "beae4c29"
      },
      "source": [
        "5. Visualizing the Results:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5351944c",
      "metadata": {
        "id": "5351944c"
      },
      "source": [
        "Visualize the transformed dataset with the first two principal components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33e282ae",
      "metadata": {
        "id": "33e282ae"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis', edgecolor='k', s=50)\n",
        "plt.title('PCA of IRIS Dataset')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.colorbar(scatter)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa9abb34",
      "metadata": {
        "id": "fa9abb34"
      },
      "source": [
        "6. Interpreting the Results:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3467bec8",
      "metadata": {
        "id": "3467bec8"
      },
      "source": [
        "The plot shows the new two-dimensional representation of the data, where the separation between the different species of Iris is still fairly clear. The explained variance ratio printed earlier tells us how much information (variance) is captured by each of the principal components. Typically, these first two components should capture a significant portion of the total variance."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b8ae634",
      "metadata": {
        "id": "2b8ae634"
      },
      "source": [
        "7. Conclusion:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ca3b9a9",
      "metadata": {
        "id": "5ca3b9a9"
      },
      "source": [
        "This example illustrates how PCA can be implemented in Python using scikit-learn to reduce the dimensionality of data, thereby simplifying the dataset while still retaining most of the critical information. PCA is particularly useful in preprocessing steps for other machine learning algorithms, which might perform poorly or overfit when dealing with high-dimensional data. By reducing the number of dimensions, PCA helps to enhance the performance and interpretability of these models."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce964580",
      "metadata": {
        "id": "ce964580"
      },
      "source": [
        "Dimensionality reduction like PCA is an invaluable tool in areas where the number of input features is too large to handle effectively, not just for simplification and visualization but also for making computational tasks more manageable and improving the performance of predictive models."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
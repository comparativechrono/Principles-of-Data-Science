{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/comparativechrono/Principles-of-Data-Science/blob/main/Week_3/Section_4_Python_Example__K_means_Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Section 4 - K-means clustering with python"
      ],
      "metadata": {
        "id": "emKhOLixYc1Z"
      },
      "id": "emKhOLixYc1Z"
    },
    {
      "cell_type": "markdown",
      "id": "065e53b7",
      "metadata": {
        "id": "065e53b7"
      },
      "source": [
        "K-means clustering is a popular and straightforward algorithm widely used in data science for partitioning data into K distinct, non-overlapping clusters. It works by assigning each data point to the nearest cluster center and then iteratively moving those centers to minimize the total variance within each cluster. This section provides a detailed example of how to implement K-means clustering using Python's scikit-learn library, demonstrating the process on a synthetic dataset to identify distinct groups based on their features."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "683d6209",
      "metadata": {
        "id": "683d6209"
      },
      "source": [
        "1. Setting Up the Environment:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10b7112a",
      "metadata": {
        "id": "10b7112a"
      },
      "source": [
        "Ensure Python and the necessary libraries are installed. For K-means clustering, we primarily need scikit-learn, numpy, and matplotlib for visualizations. Install them using pip if they are not already installed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79ac8324",
      "metadata": {
        "id": "79ac8324"
      },
      "outputs": [],
      "source": [
        "pip install numpy matplotlib scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68a540a7",
      "metadata": {
        "id": "68a540a7"
      },
      "source": [
        "2. Importing Required Libraries:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55f0b4a4",
      "metadata": {
        "id": "55f0b4a4"
      },
      "source": [
        "Start by importing the libraries necessary for creating the dataset, performing the clustering, and visualizing the results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef07ad39",
      "metadata": {
        "id": "ef07ad39"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import KMeans"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "122756d6",
      "metadata": {
        "id": "122756d6"
      },
      "source": [
        "3. Generating Synthetic Data:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "111c91d6",
      "metadata": {
        "id": "111c91d6"
      },
      "source": [
        "To demonstrate K-means, we'll create a synthetic dataset with clear clusters using make_blobs, which is useful for generating data with Gaussian distributions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5b063ae",
      "metadata": {
        "id": "f5b063ae"
      },
      "outputs": [],
      "source": [
        "# Generate synthetic data with 3 clusters\n",
        "X, y = make_blobs(n_samples=300, centers=3, cluster_std=0.60, random_state=0)\n",
        "\n",
        "# Plot the data\n",
        "plt.scatter(X[:,0], X[:,1], s=50)\n",
        "plt.title(\"Synthetic Data for Clustering\")\n",
        "plt.xlabel(\"Feature 1\")\n",
        "plt.ylabel(\"Feature 2\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0420565e",
      "metadata": {
        "id": "0420565e"
      },
      "source": [
        "4. Applying K-means Clustering:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24a59022",
      "metadata": {
        "id": "24a59022"
      },
      "source": [
        "We'll apply K-means clustering to this dataset, specifying the number of clusters we expect (which is 3 in this case):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0ab1ce9",
      "metadata": {
        "id": "c0ab1ce9"
      },
      "outputs": [],
      "source": [
        "# Create a K-means clustering model\n",
        "kmeans = KMeans(n_clusters=3)\n",
        "\n",
        "# Fit the model to the data\n",
        "kmeans.fit(X)\n",
        "\n",
        "# Predict the cluster labels\n",
        "y_kmeans = kmeans.predict(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44895ed7",
      "metadata": {
        "id": "44895ed7"
      },
      "source": [
        "5. Visualizing the Clusters:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffbb4612",
      "metadata": {
        "id": "ffbb4612"
      },
      "source": [
        "Visualize the resulting clusters and the centroids to understand how well the algorithm has performed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "296d6c9e",
      "metadata": {
        "id": "296d6c9e"
      },
      "outputs": [],
      "source": [
        "# Scatter plot of the data with the color indicating the cluster\n",
        "plt.scatter(X[:,0], X[:,1], c=y_kmeans, s=50, cmap='viridis', marker='o', alpha=0.6, label='Data Points')\n",
        "centers = kmeans.cluster_centers_\n",
        "\n",
        "# Scatter plot for the centroids\n",
        "plt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, alpha=0.75, marker='X', label='Centroids')\n",
        "plt.title(\"K-means Clustering\")\n",
        "plt.xlabel(\"Feature 1\")\n",
        "plt.ylabel(\"Feature 2\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2299be0",
      "metadata": {
        "id": "a2299be0"
      },
      "source": [
        "6. Evaluation and Analysis:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e026dc3e",
      "metadata": {
        "id": "e026dc3e"
      },
      "source": [
        "After visualizing the clusters, evaluate the model's effectiveness. A common approach is to look at the within-cluster sum of squares (inertia), which K-means tries to minimize:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99e4f363",
      "metadata": {
        "id": "99e4f363"
      },
      "outputs": [],
      "source": [
        "print(\"Model Inertia:\", kmeans.inertia_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "313da284",
      "metadata": {
        "id": "313da284"
      },
      "source": [
        "7. Conclusion:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47ddd101",
      "metadata": {
        "id": "47ddd101"
      },
      "source": [
        "This example illustrates how K-means clustering works and how it can be implemented in Python using scikit-learn. The algorithm is efficient and effective for a wide range of simple clustering problems. However, it requires the number of clusters to be known beforehand and assumes that the clusters are isotropic. K-means can perform poorly on complex geometries or clusters of varying sizes and densities. For real-world applications, it's important to preprocess the data appropriately and consider the algorithm's assumptions when interpreting the results."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}